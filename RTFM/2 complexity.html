<!DOCTYPE html>
<!--[if IE 7]>
<html lang="ru" class="ie7">
<![endif]-->
<!--[if IE 8]>
<html lang="ru" class="ie8">
<![endif]-->
<!--[if (lt IE 7)|(gt IE 8)]><!-->
<html lang="ru">
<!--<![endif]-->
<head>
    <title>Алгоритмическая сложность</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="https://dl.dropboxusercontent.com/u/31437201/article.css">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
</head>
<body>
    <article class="page">
        <h1>Алгоритмическая сложность</h1>
        <section>
            <h2 id="main">Коротко о главном</h2>
            <h4>Цель статьи</h4>
            <p>
                Данная статья преследует несколько основных целей. Вы должны здраво представлять себе что такое алгоритмическая сложность (time complexity) и пространственная сложность (space complexity). Это первое. Я (и не только я, к стати) уже немного устал повторять одно и то же один раз в неделю на консультациях и периодически на уикендах. Это второе. Поэтому, раз уж сошлись мои меркантильные и ваши образовательные интересы - получайте статью. Я не буду в статье вдаваться в сложный матан и незаурядные формулировки, а всего лишь постараюсь донести до вас общее, но здравое понимание сложности алгоритмов.
            </p>
            <h4>Зачем мне это?</h4>
            <p>
                Это вполне естественный вопрос. Существует много мнений, что в двадцать первом веке оценивать алгоритмы и экономить производительность - это рудиментарное явление. Поскольку процессоры эволюционируют семимильными шагами, а от объемов памяти захватывает дух. Бред. Если вы сами не можете сейчас ответить себе на вопрос, почему же это бред - дальше можете не читать. Вам не по пути с программированием.
            </p>
            <p>
                Итак, зачем вам понимать сложность алгоритмов и уметь оные оценивать? Отвечу. Вы будете частенько встречаться с необходимостью выбора определенных алгоритмов при реализации задач в программировании. Например, вам нужно будет выбрать какой-нибудь контейнер для хранения и обработки данных. Это может быть массив или связный список, множество или карта, etc. Вы всегда сможете прикинуть какие операции будут приоритетными: добавление и удаление элементов, поиск элементов либо всяческие изменения и махинации со значениями. Зная сложность таких операций как добавление, удаление, поиск и обращение к элементу, и имея представление о том, какие операции для вашей задачи будут приоритетными, вы без труда выберите наиболее оптимальный контейнер. Либо же перед вами может стоять другая задача: выбрать наиболее оптимальный алгоритм для обработки числовой последовательности. Умея оценить характер последовательности и сложность алгоритмов для обработки, вы решите задачу с минимальными потерями производительности. Примеров тысячи.
            </p>
            <p>
                Я думаю хватит для вводной части. Перейдем к делу.
            </p>
            <h4>Собственно сабж.</h4>
            <p>
                Википедия учит нас, что:
            </p>
            <blockquote>
                Вычислительная сложность — понятие в информатике и теории алгоритмов, обозначающее функцию зависимости объёма работы, выполняемой некоторым алгоритмом, от размера входных данных.
            </blockquote>
            <p>
                И по большому счету, это похоже на правду. Единственное, что всегда забывают википузики, это то, что не только размер имеет значение. Но у них видимо какие-то комплексы по этому поводу. Поэтому, если спросят нас, мы ответим, что алгоритмическая сложность - это зависимость объема работы, выполняемой алгоритмом от размера и характера входящих данных.
            </p>
            <p>
                Вопрос состоит в следующем: как мы можем оценить работу? В каких единицах ее измерить? Это пожалуй самая сложная часть, которую нам придется осознать! Итак, для старта напишем простой и понятный вам алгоритм.
            </p>
            <code data-lang="c" data-file="complexity.c">for ( int i = 0; i &lt; N; i++ ) {
    printf(&quot;%d &quot;, i);
}
printf(&quot;%d\n&quot;, N);</code>
            <p>
                Не очень сложно, правда? Мы написали алгоритм, который выводит в строку последовательность чисел от <code>0</code> до <code>N</code>. Теперь давайте разберемся, что же из написаного нами кода выполняет полезную работу. Видимо, это функция <code>printf()</code>. Для пущей наглядности поясню, что при <code>N == 5</code>, работа нашего алгоритма будет выглядеть следующим образом:
            </p>
            <code data-lang="c" data-file="complexity.c">printf(&quot;%d &quot;, 0);
printf(&quot;%d &quot;, 1);
printf(&quot;%d &quot;, 2);
printf(&quot;%d &quot;, 3);
printf(&quot;%d &quot;, 4);
printf(&quot;%d\n&quot;, 5);</code>
            <p>
                Цикл, по факту, только регламентирует количество повторений вызовов функции <code>printf()</code>. Теперь, с осознанием того, что полезную работу выполняет функция <code>printf()</code>, мы можем смело принять каждый ее вызов за единицу работы. Учитывая, что такая работа выполняется заданное количество раз, мы можем определить зависимость. В нашем случае, количество вызовов <code>printf()</code> будет зависить от значения <code>N</code>. То есть алгоритмическая сложность нашего алгоритма можно записать как <code>O(N)</code>. И таки да, алгоритмическая сложность выражается как функция <code>O()</code> [&quot;о&quot; большое].
            </p>
            <p>
                Итак, подытожим: работа измеряется в абстрактных единицах. За единицу работы мы принимаем выполнение каких либо элементарных действий. Это могут быть вызовы функций, какие-нибудь вычисления, логические операции и так далее. Если данный процесс визуализировать, мы получим следущее:
            </p>
            <figure>
                <img src="c1.png" alt="" width="350">
                <figcaption>Рис. 1</figcaption>
            </figure>
            <p>
                Я специально абстрагировался от написания конкретного кода в заголовке цикла (Рис. 1), чтобы не формировать у вас ненужные стереотипы. Ибо у нас не всегда будут простые и очевидные зависимости.
            </p>
            <p>
                Если вы внимательно читали все описаное ранее, тогда вам не сложно догадаться, что &quot;некая полезная работа&quot; (Рис. 1) - это и есть та самая абстрактная единица работы, которой мы пользуемся при оценке сложности алгоритма. И если вам необходимо будет представить, сколько же единиц работы будет выполнено, просто прикиньте сколько раз изменится <code>init</code>, пока выполняется <code>condition</code>, учитывая то, как <code>init</code> изменяется под воздействием <code>modificators</code>. Ну не мне вам рассказывать как работает цикл. Но для верности, давайте таки визуализируем простенький цикл.
            </p>
            <p>
                Код:
            </p>
            <code data-lang="c" data-file="complexity.c">for ( int i = 0; i &lt; N; i++ ) {
    // some calculations
}</code>
            <p>
                Визуализация:
            </p>
            <figure>
                <img src="c2.jpg" alt="" width="750">
                <figcaption>Рис. 2</figcaption>
            </figure>
            <p>
                Если представить, что желтые квадраты (Рис. 2) - это те самые &quot;some calculations&quot; из кода, который написан выше, то все становится на свои места. Сложно? Пока норм, правда?
            </p>
            <p>
                Теперь немного иного кода:
            </p>
            <code data-lang="c" data-file="complexity.c">for ( int k = 0; k &lt; N; k++ ) {
    for ( int i = 0; i &lt; N; i++ ) {
        // some calculations
    }
}</code>
            <p>
                Как мы видим, задача немного усложнилась. Придется вспоминать как работают вложенные циклы. Припомним задачу, в которой нужно было нарисовать в консоли числовой квадрат. Помните? Нам на вход подается некое число <code>total</code>, и нам, отталкиваясь от этого, необходимо нарисовать в консоли квадрат, состояший из <code>total</code> строк, по <code>total</code> чисел в каждой. Двайте напишем решение:
            </p>
            <code data-lang="c" data-file="square.c">#include &lt;stdio.h&gt;

int main() {
    int total;

    scanf("%d", &amp;total);

    for ( int row = 1; row &lt;= total; row++ ) {
        for ( int col = 1; col &lt; total; col++ ) {
            printf("%d ", col);
        }
        printf("%d\n", total);
    }

    return 0;
}</code>
            <p>
                Скомпилируем и запустим код:
            </p>
            <kbd>gcc -std=c99 square.c -o square.exe &amp;&amp; square.exe
5
1 2 3 4 5
1 2 3 4 5
1 2 3 4 5
1 2 3 4 5
1 2 3 4 5</kbd>
            <p>
                Очень внезапно, но мы получили числовой квадрат. Теперь давайте произведем некоторые калькуляции. Кто у нас рабочая лошадка в данной задаче? Видимо опять функция <code>printf()</code>. Теперь прикинем, сколько раз выполнилась функция, если извесно, что она выводит одно число, а чисел было выведено двадцать пять.
                Видимо функция отрабатывала двадцать пять раз. Теперь будем вычислять зависимость. На вход подали <code>5</code> и было выполнено <code>25</code> единиц работы.
                Если бы на вход было подано <code>6</code>, было бы выполнено <code>36</code> единиц работы, если <code>7</code> - <code>49</code>, если <code>9</code> - <code>81</code>. Улавливаете зависимость? Ну конечно же это <code>O(N<sup>2</sup>)</code>.
            </p>
            <p>
                Набросаем принципиальную схему:
            </p>
            <figure>
                <img src="c3.png" alt="" width="500">
                <figcaption>Рис. 3</figcaption>
            </figure>
            <p>
                Как видите (Рис. 3), мы имеем цикл, на каждой итерации которого выполняется еще один цикл. Во вложенном цикле происходит некая работа. И если мы вернемся к более раннему образцу кода:
            </p>
            <code data-lang="c" data-file="complexity.c">for ( int k = 0; k &lt; N; k++ ) {
    for ( int i = 0; i &lt; N; i++ ) {
        // some calculations
    }
}</code>
            <p>
                Мы сразу заметим, что каждая итерация внешнего цикла, провоцирует выполнение <code>N</code> единиц работы. Сам же внешний цикл выполняется <code>N</code> раз. Таким образом мы имеем <code>N * N = N<sup>2</sup></code> единиц выполненой работы и утверждаем, что сложность такого алгоритма <code>O(N<sup>2</sup>)</code>. Справедливо? Я думаю, что вполне справедливо. Для наглядносли проиллюстрирую:
            </p>
            <figure>
                <img src="c4.png" alt="" width="750">
                <figcaption>Рис. 4</figcaption>
            </figure>
            <p>
                Теперь давайте-ка определимся с основными зависимостями:
            </p>
            <table>
                <thead>
                    <tr>
                        <th>O()</th>
                        <th>Название</th>
                        <th>Пример</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>O(1)</code></td>
                        <td>Константная зависимость</td>
                        <td><code>for ( int i = 0; i &lt; 10; i++ ) { some code }</code></td>
                    </tr>
                    <tr>
                        <td><code>O(logN)</code></td>
                        <td>Логарифмическая зависимость</td>
                        <td><code>for ( int i = 1; i &lt; N; i *= 3 ) { some code }</code></td>
                    </tr>
                    <tr>
                        <td><code>O(log<sup>2</sup>N)</code></td>
                        <td>---</td>
                        <td>
                            <code>for ( int i = N; i &gt; 0; i /= 5 ) {
    for ( int j = 1; j &lt; N; j *= 7 ) {
        some code
    }
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N)</code></td>
                        <td>Линейная зависимость</td>
                        <td><code>for ( int i = N; i &gt; 0; i-- ) { some code }</code></td>
                    </tr>
                    <tr>
                        <td><code>O(NlogN)</code></td>
                        <td>---</td>
                        <td>
                            <code>for ( int i = N; i &gt; 0; i -= 5 ) {
    for ( int j = 1; j &lt; N; j *= 7 ) {
        some code
    }
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N<sup>2</sup>)</code></td>
                        <td>---</td>
                        <td>
                            <code>for ( int i = 0; i &lt; N; i++ ) {
    for ( int j = 0; j &lt; i; j++ ) {
        some code
    }
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N<sup>3</sup>)</code></td>
                        <td>---</td>
                        <td>
                            <code>for ( int i = 0; i &lt; N; i++ ) {
    for ( int j = 0; j &lt; i; j++ ) {
        for ( int k = N; k &gt; 0; k-- ) {
            some code
        }
    }
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(2<sup>N</sup>)</code></td>
                        <td>Экспоненциальная зависимость</td>
                        <td><code>for ( int i = 1; i &lt; (1 &lt;&lt; N); i++ ) { some code }</code></td>
                    </tr>
                    <tr>
                        <td><code>O(&infin;)</code></td>
                        <td>Бесконечность</td>
                        <td><code>for ( ; ; ) { some code }</code></td>
                    </tr>
                </tbody>
            </table>
            <p>
                И это еще не все! Вполне себе можно реализовать алгоритмы со сложностью <code>O(N<sup>4</sup>)</code>, <code>O(N<sup>5</sup>)</code>, <code>O(N<sup>N</sup>)</code>, <code>O(N!)</code> и еще много чего. И как вы могли заметить я не везде писал названия, потому что <code>O(N<sup>2</sup>)</code> произносится ВНЕЗАПНО! как &quot;о от эн квадрат&quot;, <code>O(log<sup>2</sup>N)</code> произносится как &quot;о от логарифм в квадрате эн&quot; и так далее.
            </p>
            <p>
                По сути своей, алгоритмическая сложность очень неточная штука. Мы определяем сложность алгоритмов не для точного подсчета тактов процессора, необходимых для выполнения задачи. Так же, определив зависимость, мы не сможем с точностью до байта определить память, которая будет задествована. Вы поймете сейчас, к чему это я.
            </p>
            <p>
                Рассмотрим несколько алгоритмов.
            </p>
            <code data-lang="c" data-file="complexity.c">// 1
for ( int k = 0; k &lt; 10; k++ ) {
    // some calculations
}

// 2
for ( int k = 0; k &lt; (N % 100); k++ ) {
    // some calculations
}

// 3
for ( int k = 0; k &lt; N; k += (N/3 + 1) ) {
    // some calculations
}

// 4
for ( int k = 0; k &lt; 100; k++ ) {
    for ( int i = 0; i &lt; 10; i++ ) {
        // some calculations
    }
}</code>
            <p>
                Итак, что объединяет эти четыре алгоритма? Скорее всего то, что все они имеют сложность <code>O(1)</code>. Почему? Объясню:
            </p>
            <ol>
                <li>
                    Выполняется строго 10 раз. Всегда.
                </li>
                <li>
                    <code>N % 100</code> дает диапазон значений от 0 до 99. Если при любых раскладах итераций цикла не может быть больше 99, его сложность константна.
                </li>
                <li>
                    Что такое <code>N/3</code>? Это третья часть числа <code>N</code>. Сколько раз к нулю нужно прибавить третью часть заданного числа чтобы получить это число? Три! Всегда три! Кто не согласен - возвращайтесь в начальную школу.
                </li>
                <li>
                    Да, там вложенный цикл. И что дальше? Суммарное количество итераций всегда будет рано 1000. Так-то.
                </li>
            </ol>
            <p>
                Сразу огорчу! Алгоритмов с константной сложностью может быть огромное количество. Запомните одно, константная сложность имеет характерную черту: количество работы не зависит от входящих данных. Если построить график такой зависимости, получится что-то типа:
            </p>
            <figure>
                <img src="1.png" alt="" width="500">
                <figcaption>O(1)</figcaption>
            </figure>
            <p>
                Круто? Это я про рисунок. Скорее всего во мне умер дизайнер. В общем, если график роста количества работы от размера входящих данных такой как на картинке - это константная сложность.
            </p>
            <p>
                Едем дальше. Еще пакован алгоритмов:
            </p>
            <code data-lang="c" data-file="complexity.c">// 1
for ( int k = 0; k &lt; N; k++ ) {
    // some calculations
}

// 2
for ( int k = 0; k &lt; N*42; k++ ) {
    // some calculations
}

// 3
for ( int k = -N; k &lt; N + 9; k += 17 ) {
    // some calculations
}

// 4
for ( int k = 8108; k &lt; N/2; k += 3 ) {
    for ( int i = 0; i &lt; 10; i++ ) {
        // some calculations
    }
}</code>
            <p>
                Как вы уже можете увидеть, все эти алгоритмы имеют сложность <code>O(N)</code>. Почему?
            </p>
            <ol>
                <li>
                    Классика жанра. Идем от нуля до <code>N</code> с шагом 1. Тут все ясно!
                </li>
                <li>
                    <code>N*42</code>, <code>N*M</code>, <code>N/4</code> - все это мы принимаем за <code>N</code>, беспринципно отбрасывая константы. Да конечно, можно спорить со случаем <code>N*M</code>, ведь значение <code>M</code> может стремиться, либо превышать <code>N</code>. Но алгоритмическая сложность вообще холиварная штука. Определить очень просто! Нужно нарисовать график! Ведь сложность <code>O(N)</code> не зря называется линейной. Значит и на графике должна быть линия не параллельная осям.
                </li>
                <li>
                    Ну по факту имеем <code>2N</code>. Ибо идем с линейным шагом (арифметическая прогрессия, для тех кто еще не въехал). Вы мне, конечно, можете сказать, что если <code>N</code> будет равняться например 3-м, то этот цикл отработает один раз. На что я вам отвечу, что ряд натуральных чисел немного бесконечен (в нашем случае ограничен размером типа <code>int</code>). А сложность алгоритма определяется по худшему варианту, и если алгоритм может работать как за <code>O(N)</code>, так и за <code>O(1)</code>, то мы будем считать, что он работает за <code>O(N)</code>.
                </li>
                <li>
                    Смотрим пункт 2 и вспоминаем константную сложность. Когда речь идет про вложенные циклы, суммарная сложность будет равняться произведению их сложностей. В нашем случае будет что-то типа <code>O(N*1) == O(N)</code>.
                </li>
            </ol>
            <p>
                В сферическом вакууме, график линейной зависимости будет выглядеть следующим образом:
            </p>
            <figure>
                <img src="2.png" alt="" width="500">
                <figcaption>O(N)</figcaption>
            </figure>
            <p>
                Теперь поговорим про сложность, когда у нас <code>N</code> в степени что-то там.
            </p>
            <code data-lang="c" data-file="complexity.c">// 1
for ( int i = 0; i &lt; N; i++ ) {
    for ( int j = 0; j &lt; N; j++ ) {
        // some calculations
    }
}

// 2
for ( int i = 1, j = 0; i &lt;= N; j++ ) {
    if ( j == N ) {
        i += 1;
        j = 0;
        // some calculations
    } else {
        // some calculations
    }
}

// 3
for ( int i = 0; i &lt; N * N; i++ ) {
    // some calculations
}

// 4
for ( int i = 0; i &lt; N; i++ ) {
    for ( int j = 0; j &lt; N; j++ ) {
        for ( int k = 0; k &lt; N; k++ ) {
            // some calculations
        }
    }
}

// 5
int limit = factorial(N);

for ( int i = 0; i &lt; limit; i++ ) {
    // some calculations
}

// 6
for ( int = 0; i &lt; (1 &lt;&lt; N); i++ ) {
    // some calculations
}</code>
            <ol>
                <li>
                    Ну вы поняли. Классика жанра.
                </li>
                <li>
                    Да, не обязательно для сложности <code>N<sup>2</sup></code> циклы должны быть вложенными. Посмотрите как изменяется <code>i</code>, и сколько раз при этом отрабатывает тело цикла. Я думаю справитесь.
                </li>
                <li>
                    Тоже должно быть все понятно.
                </li>
                <li>
                    Типичный куб.
                </li>
                <li>
                    Факториал. Ну, либо же кто-то назвал факториалом другую функцию, что вряд ли.
                </li>
                <li>
                    <code>O(2<sup>N</sup>)</code>.
                </li>
            </ol>
            <p>
                Опять-таки если намалевать график такой зависимости, то опыт школьной программы и google подсказывают нам, что это будет парабола:
            </p>
            <figure>
                <img src="5.png" alt="" width="500">
            </figure>
            <p>
                Логарифмическими зависимостями все немного интереснее. Ведь мы на самом деле не вычисляем логарифм в классическом понимании этого термина. Мы называем зависимость логарифмической, когда количество работы таки зависит от входящих данных, но до линейной сложности еще не дотягивает. Например:
            </p>
            <code data-lang="c" data-file="complexity.c">// 1
for ( int i = N; i &gt; 1; i /= 2 ) {
    // some calculations
}

// 2
for ( int i = 1; i &lt; N; i *= 4 ) {
    // some calculations
}


// 3
for ( int i = 0; i &lt; ( N % 87 ) + 4; i += 11 ) {
    for ( int j = 2; j &lt; N + 3489; j *= 3 ) {
        // some calculations
    }
}</code>
            <p>
                Да, это все алгоримы имеющие сложность <code>O(logN)</code>. Как такое может быть? Очень просто! Прирост не линейный. Разберем на простых примерах:
            </p>
            <code data-lang="c" data-file="complexity.c">// 1
for ( int i = 1; i &lt; N; i++ ) {
    // some calculations
}

// 2
for ( int i = 1; i &lt; N; i *= 2 ) {
    // some calculations
}</code>
            <p>
                Зададим этим 2-м циклам 10 в качестве значения <code>N</code>. Как будет увеличиваться <code>i</code> в первом случае? Примерно с шагом в <code>1</code>. То есть мы получим что-то типа: <code>1 2 3 4 5 6 7 8 9</code>. Что будет во втором случае? <code>1 2 4 8</code>. Теперь задайте 100 в качестве значения <code>N</code> и посмотрите что получится. То есть количество выполненной работы все-же зависит от входящих данных, но сложность гораздо меньше линейной. Такую зависимость мы будем считать логарифмической. Если построим график, то получим что-то типа:
            </p>
            <figure>
                <img src="3.png" alt="" width="500">
                <figcaption>O(logN)</figcaption>
            </figure>
            <p>
                Теперь я надеюсь, ситуация стала немного понятней? Потому что дальше мы будем говорить о функциях. Я надеюсь вы все помните что такое функция. Для начала потренируемся на кошках. Напишем примеры очень простых функций на каждую из сложностей.
            </p>
            <table>
                <thead>
                    <tr>
                        <th>O()</th>
                        <th>Название</th>
                        <th>Пример</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>O(1)</code></td>
                        <td>Константная зависимость</td>
                        <td><code>int bench(int n) {
    int result = 0;

    for ( int i = 0; i &lt; 10; i++ ) {
        result += n;
    }

    return result;
}</code></td>
                    </tr>
                    <tr>
                        <td><code>O(logN)</code></td>
                        <td>Логарифмическая зависимость</td>
                        <td><code>int bench(int n) {
    int result = 1;

    for ( int i = 1; i &lt; n; i *= 3 ) {
        result *= 2;
    }

    return result;
}</code></td>
                    </tr>
                    <tr>
                        <td><code>O(log<sup>2</sup>N)</code></td>
                        <td>---</td>
                        <td>
                            <code>int bench(int n) {
    int result = 0;

    for ( int i = n; i &gt; 0; i /= 5 ) {
        for ( int j = 1; j &lt; n; j *= 7 ) {
            result += 1;
        }
    }

    return result;
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N)</code></td>
                        <td>Линейная зависимость</td>
                        <td><code>int bench(int n) {
    int result = 0;
    
    for ( int i = n; i &gt; 0; i-- ) {
         result += 1;
    }

    return result;

}</code></td>
                    </tr>
                    <tr>
                        <td><code>O(NlogN)</code></td>
                        <td>---</td>
                        <td>
                            <code>int bench(int n) {
    int result = 0;

    for ( int i = n; i &gt; 0; i -= 5 ) {
        for ( int j = 1; j &lt; n; j *= 7 ) {
            result += 1;
        }
    }

    return result;
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N<sup>2</sup>)</code></td>
                        <td>---</td>
                        <td>
                            <code>int bench(int n) {
    int result = 0;

    for ( int i = 0; i &lt; n; i++ ) {
        for ( int j = 0; j &lt; i; j++ ) {
            result += 1;
        }
    }

    return result;
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(N<sup>3</sup>)</code></td>
                        <td>---</td>
                        <td>
                            <code>int bench(int n) {
    int result = 0;
    
    for ( int i = 0; i &lt; n; i++ ) {
        for ( int j = 0; j &lt; i; j++ ) {
            for ( int k = n; k &gt; 0; k-- ) {
                rtesult += 1;
            }
        }
    }

    return result;
}</code>
                        </td>
                    </tr>
                    <tr>
                        <td><code>O(2<sup>N</sup>)</code></td>
                        <td>Экспоненциальная зависимость</td>
                        <td><code>int bench(int n) {
    int result = 0;

    for ( int i = 1; i &lt; (1 &lt;&lt; n); i++ ) {
        result += 1;
    }

    return result;
}</code></td>
                    </tr>
                    <tr>
                        <td><code>O(&infin;)</code></td>
                        <td>Бесконечность</td>
                        <td><code>int bench(int n) {
    int result = 0;
    
    for ( ; ; ) {}
    
    return 4;
}</code></td>
                    </tr>
                </tbody>
            </table>
            <p>
                Я думаю не нужно быть физиком-ядерщиком, инженером с семилетним стажем или иметь 2 высших образования, чтобы понять сложность данных мощных функций. По сути, я взял код из предыдущей таблицы и завернул в функции. Сложность не изменилась. На каждый вызов функции полезная работа выполняется какое-то количество раз. Вас может смутить конечно, что код переехал в область видимости конкретных функций. Но раньше он жил в теле функции <code>main()</code> и вас это особо не смущало, так ведь? Но для пущей убедительности моих слов, найдите-ка десять отличий:
            </p>
            <code data-lang="c" data-file="complexity.c">#include &lt;stdio.h&gt;

int main() {
    int n;
    int result = 0;

    scanf(&quot;%d&quot;, &amp;n);
    
    for ( int i = 0; i &lt; n; i++ ) {
        for ( int j = 0; j &lt; i; j++ ) {
            for ( int k = n; k &gt; 0; k-- ) {
                rtesult += 1;
            }
        }
    }

    printf(&quot;%d\n&quot;, result);

    return 0;
}</code>
            <p>
                Это первый мощный образец. Теперь второй:
            </p>
            <code data-lang="c" data-file="complexity.c">#include &lt;stdio.h&gt;

int bench(int n) {
    int result = 0;

    for ( int i = 0; i &lt; n; i++ ) {
        for ( int j = 0; j &lt; i; j++ ) {
            for ( int k = n; k &gt; 0; k-- ) {
                rtesult += 1;
            }
        }
    }

    return result;
}

int main() {
    int n;

    scanf(&quot;%d&quot;, &amp;n);
    
    printf(&quot;%d\n&quot;, bench(n));

    return 0;
}</code>
            <p>
                Начинаете меня понимать? А я уже несколько лет живу с этим знанием. И, к тому же тяжело найти отличия там, где их нет. Ну хотя-бы с точки зрения алгоритмической сложности. Поэтому делаем вывод, что оценка алгоритмической сложности отдельной функции ничем особо не отличается. Ну конечно, если это не рекурсивная функция. О них сейчас и пойдет разговор.
            </p>
            <p>
                Ну про преимущества и недостатки рекурсии вы уже должны были быть наслышаны. И более того, чтобы реализовать такую функцию, нам необходимо смастерить ее рекуррентное соотношение. О как! Удивлены? Ну только не нужно мне рассказывать про то, что вы не знаете, что рекуррентное соотношение - это формула, которая выражает каждый член последовательности через <code>n</code> предыдущих членов. Рекуррентное соотношение для факториала числа будет выглядеть как <code>f(n!) = f(n-1)! * n</code>, для положительных чисел фибоначи как <code>f(n) = f(n-1) + f(n-2)</code> и так далее.
            </p>
            <p>
                Начнем с чего-нибудь попроще! Например с факториала числа.
            </p>
            <code data-lang="c" data-file="complexity.c">int factorial(int n) {
    if ( n &lt;= 1 ) {
        if ( n &lt; 0 ) {
            return -1;
        }
        return 1;
    }
    return factorial(n-1) * n;
}</code>
            <p>
                Я надеюсь все вспомнили как работает рекурсивная функция. Функция будет вызываться до тех пор, пока не срабатывает условие выхода. Если мы вызовем функцию для <code>n == 5</code>, получим следующее:
            </p>
            <figure>
                <img src="c5.png" alt="" width="500">
                <figcaption>factorial function</figcaption>
            </figure>
            <p>
                Как вы можете заметить, работа функции невероятно проста. Остается вопросом только одно: что же мы будем считать полезной работой? Отвечу - полезной работой будут считаться все инструкции, которые выполняются в области видимости функции. Итак, для поиска <code>5!</code> функция вызывалась 5 раз. Значит все инструкции, которые находятся в области видимости функции тоже выполнялись 5 раз. Соответственно мы выполнили 5 единиц полезной работы. Поэтому алгоритмическая сложность данного решения - <code>O(N)</code>. Очень сложно, не правда ли?
            </p>
            <p>
                Теперь рассмотрим вариант посложнее! Фибоначчи:
            </p>
            <code data-lang="c" data-file="complexity.c">int fibonacci(int n) {
    if ( n == 0 ) {
        return 0;
    }
    if ( n == 1 || n == -1 ) {
        return 1;
    }
    if ( n &lt; 0 ) {
        return fibonacci(n+2) - fibonacci(n+1);
    }
    return fibonacci(n-1) + fibonacci(n-2);
}</code>
            <p>
                Применим рисование (боюсь, что мне это уже нравится). Получим схемку:
            </p>
             <figure>
                <img src="c6.png" alt="" width="800">
                <figcaption>fibonacci function</figcaption>
            </figure>
            <p>
                Итак, как вы можете заметить, каждый вызов функции инициирует еще 2 вызова. Таким образом количество вызовов растет экспоненциально. Попробуйте найти 42 число Фибоначчи используя рекурсивную реализацию алгоритма.Сколько времени у вас это займет? Много... А жизнь так коротка! Поэтому можно преобразовать рекурсивные функции для поиска факториала и чисел Фибоначчи в циклы, и существенно сэкономить расход ресурса. Но так или иначе, сложность рекурсивного алгоритма для поиска чисел Фибоначчи - <code>O(2<sup>N</sup>)</code>.
            </p>
            <p>
                Схемы я больше рисовать не буду - после Фибоначчи мне это надоело, вместо этого рассмотрим еще один случай.
            </p>
            <code data-lang="c" data-file="complexity.c">int bench(int n) {
    if ( n &lt;= 0 ) {
        return 0;
    }
    
    return bench(n/2) + bench(n/2);
}</code>
            <p>
                Казалось бы все просто! <code>O(2<sup>N</sup>)</code>, да и делу конец. Однако нет, мы немного поразмышляем. Для начала реализуем пару простеньких случаев:
            </p>
            <code data-lang="c" data-file="complexity.c">int bench1(int n) {
    if ( n &lt;= 0 ) {
        return 0;
    }
    
    return bench1(n-1);
}

int bench2(int n) {
    if ( n &lt;= 0 ) {
        return 0;
    }
    
    return bench2(n/2);
}</code>
            <p>
                Для осознания масштаба трагедии, вспомним недавно рассмотренные случаи с циклами: <code>for ( int i = n; i &gt; 0; i--)</code> и <code>for ( int i = n; i &gt; 0; i /= 2 )</code>. Я больше чем уверен, что вы без всякого труда определите сложность данных циклов, это <code>O(N)</code> и <code>O(logN)</code> соответственно. Если вы внимательно посмотрите на рекурсивные функции, реализованные чуть выше, вы прийдете к выводу, что их сложность идентична: bench1() - <code>O(N)</code>, bench2() - <code>O(logN)</code>. Не верите мне, нарисуйте схемку, как я вам показывал на примере <code>factorial</code> и нарисуйте график. Сами все увидите.
            </p>
            <p>
                Так вот, не будем отклоняться от темы. Итак, наш случай:
            </p>
            <code data-lang="c" data-file="complexity.c">int bench(int n) {
    if ( n &lt;= 0 ) {
        return 0;
    }
    
    return bench(n/2) + bench(n/2);
}</code>
            <p>
                Рекуррентное соотношение данной функции <code>f(n) = f(n/2) + f(n/2)</code>. Напомню, что рекуррентное соотношение функции для поиска чисел Фибонначи выражалось как <code>f(n) = f(n-1) + f(n-2)</code> и реализация рекурсивного алгоритма имела сложность <code>2<sup>N</sup></code>. В случае с <code>f(n) = f(n/2) + f(n/2)</code>, мы имеем явно нелинейную зависимость, и сложность будет <code>2<sup>log<sub>2</sub>N</sup></code>. 
            </p>
            <p>
                Применив немного элементарной алгебры, мы вспомним (или узнаем), что <code>2<sup>log<sub>2</sub>N</sup> = N</code>. За подробностями в google или в учебник по алгебре за 8-9 класс.
            </p>
            <p>
                Но это слишком примитивные примеры. Давайте рассмотрим что-то веселое. Например такую функцию: 
            </p>
            <code data-lang="c" data-file="complexity.c">int bench(int n) {
    if ( n == 0 ) {
        return 0;
    }

    if ( n &lt; 0 ) {
        return bench(n+1);
    }

    return bench(n-1) + bench(-n);
}</code>
            <p>
                Немного интереснее, правда? Но давайте применим немного мозга. На вход подается некое число <code>n</code>. В результате функция провоцирует два вызова самой себя для положительного и отрицательного числа. Что происходит дальше? Дальше положительная ветка провоцирует еще два вызова. В отрицательной ветке срабатывает условие <code>if ( n &lt; 0 )</code> и отрабатывает <code>return bench(n+1);</code>. <code>return</code>, в свою очередь, провоцирует вызовы отрицательной ветки, пока не отработает условие выхода. Учитывая, что <code>n</code> в этот момент отрицательный и шаг <code>+1</code>, то делаем вывод, что прежде чем выполнится условие выхода, отрицательная ветка отработает <code>n</code> раз. Теперь подводим итоги: на каждый вызов положительной ветки происходит <code>n</code> вызовов отрицательной, поэтому суммарная сложность этой функции <code>O(N * N) = O(N<sup>2</sup>)</code>. Все оказалось просто.
            </p>
            <p>
                Ну и как всегда, самое главное на последок. Настало время различать пространственную и временную сложность. Все, о чем я писал выше имеет отношение к временной сложности. Поскольку нас там интересовало время выполнения. Поясню! Мы с вами научились вычислять абстрактные единицы работы. Так вот каждая единица работы требует абстрактную единицу времени для выполнения. По факту, количество единиц работы будет равняться количеству единиц времени которые нам нужно затратить. Поэтому если получив на вход <code>N</code>, мы выполняем <code>N<sup>2</sup></code> единиц работы, мы тем самым тратим и <code>N<sup>2</sup></code> единиц времени. Поэтому мы говорим что временная сложность такого решения - <code>O(N<sup>2</sup>)</code>
            </p>
            <p>
                Теперь поговорим про пространственную сложность. Что это такое? Мы уже выяснили, что для выполнения некоторого количества работы необходимо затратить некоторое количество времени. Но кроме времени есть еще один замечательный ресурс! И имя ему - память! Давайте рассмотрим некоторую абстрактную задачу. Дан массив, длинной в <code>N</code> элементов. Нам необходимо произвести реверс массива. Реализация данной задачи может выглядеть следующим образом:
            </p>
            <code data-lang="c" data-file="complexity.c">void arrayReverse(int array[], int size) {
    for ( int i = 0, j = size - 1; i &lt; j; i++, j-- ) {
        int tmp = array[i];
        
        array[i] = array[j];
        array[j] = tmp;
    }
}</code>
            <p>
                Мы без труда определим временную сложность - <code>O(N)</code>. Это легко и просто, ведь у нас за плечами уже громадный опыт. Но что делать с пространственной сложностью? Что учитывать? Что не учитывать? Как оценить? Куда смотреть? Отвечу! Все очень просто. То что у нас изначально было, учитывать не нужно. Нам необходимо учитывать лишь ту память, которую мы выделяли дополнительно. То есть в данной задаче, мы не учитываем <code>int array[]</code>, поскольку он к нам пришел извне. Мы будем учитывать только то, что мы объявили в реализации алгоритма. А что мы там объявили? Ого! Аж одну переменную <code>int tmp;</code>. Итого, чтобы осуществить реверс массива, нам понадобилось объявить одну дополнительную переменную.
            </p>
            <p>
                Пространственная сложность - <code>O(1)</code>.
            </p>
            <p>
                Теперь подумаем над другой абстрактной задачей. Есть массив размером <code>N</code> элементов. Нам его необходимо сдвинуть на <code>shift</code> элементов. Как мы это можем сделать? Вариант #1 (жлобский):
            </p>
            <figure>
                <img src="c7.png" alt="" width="800">
                <figcaption>Сдвиг массива</figcaption>
            </figure>
            <p>
                Суть данного подхода очень проста. Мы сдвигаем массив на 1 элемент и повторяем данную процедуру <code>shift</code> раз. Если нам необходимо сдвинуть массив на <code>N</code> элементов, то процедуру сдвига мы должны повторить <code>N</code> раз. При таком подходе, временная сложность решения - <code>O(N<sup>2</sup>)</code>, пространственная сложность <code>O(1)</code>, ведь для реализации этого нам потребовалась аж одна дополнительная переменная.
            </p>
            <p>
                Подход #2 (неоправданная щедрость):
            </p>
            <figure>
                <img src="c8.png" alt="" width="800">
                <figcaption>Сдвиг массива</figcaption>
            </figure>
            <p>
                Суть данного подхода в выделении такого же массива и целенаправленной расстановке элементов на нужные места. Чтобы не оставалось магии в словосочетании &quot;целенаправленная расстановка&quot; открою секрет - решается двумя простыми циклами. Временная сложность уменьшилась до <code>O(N)</code>. Это успех. Но пространственная сложность выросла до <code>O(N)</code>. Это позор. Почему пространственная сложность выросла до <code>O(N)</code>? Ну если для выполнения операции над массивом из <code>N</code> элементов необходимо выделить дополнительный массив из <code>N</code> элементов... По моему, очевидно!
            </p>
            <p>
                Вариант #3 (разумный компромисс):
            </p>
            <figure>
                <img src="c9.png" alt="" width="800">
                <figcaption>Сдвиг массива</figcaption>
            </figure>
            <p>
                Суть данного подхода в выделении подмассива на <code>shift</code> элементов. Вы можете сказать, что если <code>shift == N</code>, тогда капец. Нет. Гений инженерной мысли подсказывает мне, что если нам нужно сдвинуть массив из <code>N</code> элементов на <code>N</code> элементов, то его сдвигать не нужно. Так же, гений инженерной мысли намекает, что если массив из 10 элементов нужно сдвинуть на 9 элементов влево, то проще сдвинуть такой массив на 1 элемент вправо. Тогда максимальный размер дополнительного массива будет равен <code>N/2</code> элементов. Итого, при таком подходе имеем <code>O(N)</code> по времени и <code>O(N/2)</code> по памяти. Выглядит разумно. И да, опять противоречие. Я не так давно утверждал, что мы отбрасываем константы, и <code>O(N/2) == O(N)</code>. Во временной сложности так и есть, потому что время - понятие философское. Но память, явление физически ощутимое и конечное. Поэтому в случае с пространственной сложность константы не игнорируются и <code>O(N/2)</code> по памяти - это, черт возьми, <code>O(N/2)</code> по памяти.
            </p>
            <p>
                Вариант #4 (памяти нет, но сдвинуть очень хочется):
            </p>
            <figure>
                <img src="c10.png" alt="" width="800">
                <figcaption>Сдвиг массива</figcaption>
            </figure>
            <p>
                Решается в три реверса.
            </p>
            <ol>
                <li>Выполняем реверс части массива подлежащей сдвигу</li>
                <li>Выполняем реверс части массива не подлежащей сдвигу</li>
                <li>Выполняем реверс всего массива</li>
            </ol>
            <p>
                Так то! По времени мы по прежнему имеем <code>O(N)</code>. Но расход памяти сократили до <code>O(1)</code>. Не спешите радоваться. Вариант #4 работаем существенно медленнее варианта #3. Поэтому, если речь идет не о программировании микроконтроллеров, вариант #4 вам вряд ли пригодится.
            </p>
            <p>
                Запомните один раз и на всю жизнь! Если вы стоите перед оптимизационным выбором что экономить: время или память? Экономьте время! Память в двадцать первом веке не проблема, а вот жизнь конечна. Да и терпение ваших потребителей тоже.
            </p>
            <p>
                Ну и немного про рекурсию. Куда же без нее! Вспоминаем что такое функция. Это именованая область памяти, в которой что-то да хранится! Поэтому каждый вызов функции таки будет провоцировать выделение дополнительной памяти. Например для хранения промежуточных значений, адреса возврата и так далее.
            </p>
            <p>
                Поэтому с рекурсией проще всего! Потребление памяти всегда соответствует глубине рекурсии. Если по времени <code>O(N)</code>, то и по памяти <code>O(N)</code>. Если по времени <code>O(N<sup>2</sup>)</code>, то и по памяти <code>O(N<sup>2</sup>)</code>. Такие вот дела.
            </p>
            <p>
                Ну и, конечно же - успехов!
            </p>
        </section>
        <footer>
            <address>
                Автор caiman.
            </address>
            <time datetime="2014-02-10">08.01.2015</time>
        </footer>
    </article>
    <script type="text/javascript" src="https://dl.dropboxusercontent.com/u/31437201/code.js"></script>
</body>
</html>